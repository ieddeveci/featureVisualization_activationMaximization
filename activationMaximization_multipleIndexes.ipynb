{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a framework for visualizing the internal representation of neural networks (ResNet18 and Vision Transformer) for specific class indexes using class activation maximization. The NetworkWrapper class preprocesses input and wraps a pretrained network, while the Visualization class generates, augments, and optimizes images to maximize the activation of a given class. \n",
    "Early stopping is implemented to save the best visualizations based on loss minimization, which includes L2 regularization to constrain image quality. The visualizations are saved as PNG images, and the process is repeated for multiple classes and models."
    "The negative of the mean target scores from the model's output for the specified class index is included in the loss. Minimizing this component effectively maximizes the model's activation for the desired class."
    "A small penalty proportional to the L2 norm of the generated image is added to the loss to constrain the generated image and prevent extreme pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "##                         Define utility functions and classes                                           ##\n",
    "############################################################################################################\n",
    "class NetworkWrapper(torch.nn.Module):\n",
    "    def __init__(self, network, preprocess_fn):\n",
    "        super(NetworkWrapper, self).__init__()\n",
    "\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        self.network = network\n",
    "        self.network.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.preprocess_fn(x)\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "\n",
    "class Visualization(torch.nn.Module):\n",
    "    def __init__(self, h, w):\n",
    "        super(Visualization, self).__init__()\n",
    "        self.__data = torch.nn.Parameter(torch.randn(1, 3, h, w))\n",
    "    \n",
    "    \n",
    "    def __augment(self, x, batch_size):\n",
    "        \n",
    "        x = torch.cat([x] * batch_size, dim=0)\n",
    "\n",
    "        # Apply random augmentations to each image in the batch\n",
    "        # For more augmentations: https://pytorch.org/vision/0.19/transforms.html\n",
    "\n",
    "        x = torchvision.transforms.RandomResizedCrop(size=[self.out_h, self.out_w], scale=(0.1, 1.0))(x)\n",
    "        \n",
    "        transforms = torch.nn.Sequential(\n",
    "            torchvision.transforms.RandomRotation(degrees=20),\n",
    "            torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "            torchvision.transforms.RandomPerspective(distortion_scale=0.4, p=0.5),\n",
    "            torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            torchvision.transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
    "        )\n",
    "        # Comment out the following line to apply random augmentations:\n",
    "        # x = transforms(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def __reparameterize(self, x):\n",
    "        x = torch.nn.functional.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def set_output_shape(self, h, w):\n",
    "        self.out_h = h\n",
    "        self.out_w = w\n",
    "\n",
    "    def forward(self, batch_size):\n",
    "        x = self.__data\n",
    "        x = self.__reparameterize(x)\n",
    "        x = self.__augment(x, batch_size)\n",
    "        return x\n",
    "\n",
    "    def to_img(self):\n",
    "        # Creating a PIL image from x\n",
    "        with torch.no_grad():\n",
    "            x = self.__data\n",
    "            x = self.__reparameterize(x)\n",
    "        x = x.squeeze(0) # Remove the batch dimension\n",
    "        x = x.cpu()\n",
    "        x = x.numpy()\n",
    "        x = np.transpose(x, (1, 2, 0))\n",
    "        x = (x * 255).clip(0, 255) # Scale pixel values from (0, 1) to (0, 255)\n",
    "        x = x.astype(np.uint8) # Converts pixels to uint8\n",
    "        pil_img = PIL.Image.fromarray(x)\n",
    "        return pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "##                         Initialize the model, visualization and optimizer                              ##\n",
    "############################################################################################################\n",
    "\n",
    "# You can enter here the class indexes you want to visualize. Example indexes:\n",
    "class_indexes = [207, 294, 398, 409, 455, 531, 681, 724, 851, 852]\n",
    "# 207 golden retriever\n",
    "# 294 brown bear, bruin, Ursus arctos\n",
    "# 398 abacus\n",
    "# 409 analog clock\n",
    "# 455 bottlecap\n",
    "# 531 digital watch\n",
    "# 681 notebook, notebook computer\n",
    "# 724 pirate, pirate ship\n",
    "# 851 television, television system\n",
    "# 852 tennis ball\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 2000  # Number of iterations to wait for improvement\n",
    "min_delta = 0.1  # Minimum change in loss to qualify as an improvement\n",
    "\n",
    "# The models that will be used for visualization\n",
    "models = {\n",
    "    \"ResNet18\": torchvision.models.resnet18(pretrained=True),\n",
    "    \"ViT\": torchvision.models.vit_b_16(pretrained=True),\n",
    "}\n",
    "\n",
    "for model_name, net in models.items():\n",
    "    print(f\"Starting visualizations for {model_name}...\")\n",
    "\n",
    "    preprocess_fn = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    model = NetworkWrapper(net, preprocess_fn).to(device)\n",
    "\n",
    "    for class_index in class_indexes:\n",
    "        print(f\"Starting visualization for class index {class_index} with {model_name}...\")\n",
    "\n",
    "        # Initialize a fresh visualization instance for each class\n",
    "        vis = Visualization(256, 256).to(device)\n",
    "        vis.set_output_shape(224, 224)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            params=vis.parameters(),\n",
    "            lr=0.2,\n",
    "        )\n",
    "\n",
    "        # Early stopping variables\n",
    "        best_loss = float('inf')\n",
    "        best_iteration = 0\n",
    "        best_vis_state = None\n",
    "        patience_counter = 0\n",
    "\n",
    "        for i in range(10000):\n",
    "            optimizer.zero_grad()\n",
    "            batch_size = 8\n",
    "            imgs = vis(batch_size).to(device)\n",
    "            outputs = model(imgs)\n",
    "            target_scores = outputs[:, class_index]\n",
    "\n",
    "            l2_regularization = torch.norm(imgs, p=2)\n",
    "            l2_lambda = 0.001\n",
    "            regularization = l2_lambda * l2_regularization\n",
    "\n",
    "            loss = -torch.mean(target_scores) + regularization\n",
    "            current_loss = loss.item()\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"{model_name} Class {class_index}, Iteration {i + 1}, Loss: {current_loss}, L2 Regularization: {regularization.item()}\")\n",
    "\n",
    "            # Check if this is the best loss\n",
    "            if current_loss < best_loss - min_delta:\n",
    "                best_loss = current_loss\n",
    "                best_iteration = i + 1\n",
    "                # Save the best visualization state\n",
    "                best_vis_state = vis.state_dict()\n",
    "                patience_counter = 0\n",
    "                \n",
    "                # Save the best visualization\n",
    "                print(f\"New best loss found! Iteration {i + 1}, Loss: {best_loss}\")\n",
    "                img = vis.to_img()\n",
    "                image_name = f\"{model_name}_class_{class_index}_best_visualization_iter_{i + 1}_loss_{best_loss:.2f}_withoutAugmentations.png\"\n",
    "                img.save(image_name)\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # Early stopping check\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered! No improvement for {patience} iterations.\")\n",
    "                print(f\"Best loss was {best_loss} at iteration {best_iteration}\")\n",
    "                break\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Load and save the best visualization one final time\n",
    "        if best_vis_state is not None:\n",
    "            vis.load_state_dict(best_vis_state)\n",
    "            final_img = vis.to_img()\n",
    "            final_image_name = f\"{model_name}_class_{class_index}_final_best_visualization_iter_{best_iteration}_loss_{best_loss:.2f}_withoutAugmentations.png\"\n",
    "            final_img.save(final_image_name)\n",
    "\n",
    "        print(f\"Visualization complete for class index {class_index} with {model_name}.\")\n",
    "        print(f\"Best loss: {best_loss} achieved at iteration {best_iteration}\")\n",
    "\n",
    "    print(f\"All visualizations complete for {model_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
