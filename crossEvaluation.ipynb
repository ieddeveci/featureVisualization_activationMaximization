{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs a cross-evaluation between two pretrained models, ResNet18 and Vision Transformer (ViT), on a dataset of images generated using activation maximization. The images are evaluated both with and without augmentation, and the accuracy of each model on different datasets is calculated. The dataset is processed using a custom Dataset class, which handles loading images and applying transformations. The evaluation function measures model performance by calculating accuracy over a series of augmented and non-augmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationMaximizationDataset(Dataset):\n",
    "    def __init__(self, path, model_type, aug_type, batch_size):\n",
    "        self.path = path\n",
    "        self.model_type = model_type\n",
    "        self.aug_type = aug_type\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # The images in the dataset should follow the following name type:\n",
    "        # {class_id}_{model_type}_{augmentation_type}.png\n",
    "        # Example: 294_Vit_withAug\n",
    "        \n",
    "        name = f\"*_{model_type}_{aug_type}.png\"\n",
    "        self.image_paths = glob.glob(os.path.join(path, name))\n",
    "        \n",
    "        self.labels = [] # Stores the labels of the images\n",
    "        self.valid_image_paths = [] # The paths to the images\n",
    "        \n",
    "        for path in self.image_paths: # Gets the class id of each image\n",
    "            class_id = int(os.path.basename(path).split('_')[0])\n",
    "            self.labels.append(class_id)\n",
    "            self.valid_image_paths.append(path)\n",
    "        \n",
    "        self.image_paths = self.valid_image_paths\n",
    "        \n",
    "        if aug_type == 'withAug': # If the image is created using random augmentations\n",
    "            self.transforms = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.RandomResizedCrop(size=[224, 224], scale=(0.1, 1.0)),\n",
    "                torchvision.transforms.RandomRotation(degrees=20),\n",
    "                torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "                torchvision.transforms.RandomPerspective(distortion_scale=0.4, p=0.5),\n",
    "                torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                torchvision.transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else: # If the image is not created using random augmentations\n",
    "            self.transforms = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.RandomResizedCrop(size=[224, 224], scale=(0.1, 1.0)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, x): # Loads and returns a batch of randomly augmented versions of an image for the given index x\n",
    "        with Image.open(self.image_paths[x]) as image:\n",
    "            image = image.convert('RGB')\n",
    "            label = self.labels[x]\n",
    "            augmented_images = [self.transforms(image) for _ in range(self.batch_size)] # Range determines the number of randomly augmented versions of the image\n",
    "            return torch.stack(augmented_images), label # Returns the batch of randomly augmented versions of the image and a vector shaped len(batch) with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(path, model_type, aug_type, batch_size=16):\n",
    "    dataset = ActivationMaximizationDataset(path, model_type, aug_type, batch_size=batch_size)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluation(path, resnet_model, vit_model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    resnet_model = resnet_model.to(device)\n",
    "    vit_model = vit_model.to(device)\n",
    "    \n",
    "    def evaluate_model(model, dataloader, model_name, aug_type):\n",
    "        model.eval()\n",
    "        true_prediction = 0\n",
    "        total_prediction = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                for i in range(images.shape[1]):  # Gets the number of augmented versions\n",
    "                    augmented_image = images[:, i, :, :, :]\n",
    "                    \n",
    "                    for j in range(len(augmented_image)):\n",
    "                        img = augmented_image[j].cpu().numpy().transpose((1, 2, 0))\n",
    "                        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                        img = img.clip(0, 1)\n",
    "                        \n",
    "                    # To visualize each image:\n",
    "\n",
    "                        # label = labels[j].item()\n",
    "                        # outputs = model(augmented_image[j].unsqueeze(0).to(device))\n",
    "                        # _, predicted = torch.max(outputs.data, 1)\n",
    "                        # predicted_label = predicted.item()\n",
    "\n",
    "                        # if label == predicted_label:\n",
    "                        #     prediction_status = \"Correct\"\n",
    "                        # else:\n",
    "                        #     prediction_status = \"Incorrect\"\n",
    "                        \n",
    "                        # model_type = \"ResNet\" if \"ResNet\" in dataloader.dataset.model_type else \"ViT\"\n",
    "\n",
    "                        # plt.figure(figsize=(4, 4))\n",
    "                        # plt.imshow(img)\n",
    "                        # plt.title(f\"Inference Model: {model_name} - Image From: {model_type}({aug_type})\\nTrue Label: {label}, Prediction: {predicted_label} ({prediction_status})\")\n",
    "                        # plt.axis(\"off\")\n",
    "                        # plt.show()\n",
    "                    \n",
    "                    augmented_image = augmented_image.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(augmented_image)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_prediction += labels.size(0)\n",
    "                    true_prediction += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = true_prediction / total_prediction\n",
    "        return accuracy\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    resnet_no_aug_loader = create_dataloader(path, 'ResNet', 'withoutAug')\n",
    "    resnet_aug_loader = create_dataloader(path, 'ResNet', 'withAug')\n",
    "    vit_no_aug_loader = create_dataloader(path, 'ViT', 'withoutAug')\n",
    "    vit_aug_loader = create_dataloader(path, 'ViT', 'withAug')\n",
    "\n",
    "    # Self-Model Accuracy\n",
    "\n",
    "    results['ViT accuracy of ViT images (not augmented)'] = evaluate_model(vit_model, vit_no_aug_loader, 'ViT', 'withoutAug')\n",
    "    results['ResNet accuracy of ResNet images (not augmented)'] = evaluate_model(resnet_model, resnet_no_aug_loader, 'ResNet', 'withoutAug')\n",
    "    results['ViT accuracy of ViT images (augmented)'] = evaluate_model(vit_model, vit_aug_loader, 'ViT', 'withAug')\n",
    "    results['ResNet accuracy of ResNet images (augmented)'] = evaluate_model(resnet_model, resnet_aug_loader, 'ResNet', 'withAug')\n",
    "\n",
    "    # Cross Evaluation Accuracy\n",
    "        \n",
    "    results['ViT accuracy of ResNet images (not augmented)'] = evaluate_model(vit_model, resnet_no_aug_loader, 'ViT', 'withoutAug')\n",
    "    results['ResNet accuracy of ViT images (not augmented)'] = evaluate_model(resnet_model, vit_no_aug_loader, 'ResNet', 'withoutAug')\n",
    "    results['ViT accuracy of ResNet images (augmented)'] = evaluate_model(vit_model, resnet_aug_loader, 'ViT', 'withAug')\n",
    "    results['ResNet accuracy of ViT images (augmented)'] = evaluate_model(resnet_model, vit_aug_loader, 'ResNet', 'withAug')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'testdataset' # Path to the images created by activation maximization\n",
    "resnet_model = torchvision.models.resnet18(pretrained=True)\n",
    "vit_model = torchvision.models.vit_b_16(weights='IMAGENET1K_V1')\n",
    "results = cross_evaluation(path, resnet_model, vit_model)\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "for test, accuracy in results.items():\n",
    "    print(f\"{test}: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
