{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions and classes with creating a PIL image from x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkWrapper(torch.nn.Module):\n",
    "    def __init__(self, network, preprocess_fn):\n",
    "        super(NetworkWrapper, self).__init__()\n",
    "\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        self.network = network\n",
    "        self.network.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.preprocess_fn(x)\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "\n",
    "class Visualization(torch.nn.Module):\n",
    "    def __init__(self, h, w):\n",
    "        super(Visualization, self).__init__()\n",
    "        self.__data = torch.nn.Parameter(torch.randn(1, 3, h, w))\n",
    "    \n",
    "    def __augment(self, x, batch_size):\n",
    "        x = torch.cat([x] * batch_size, dim=0)\n",
    "\n",
    "        transforms = torch.nn.Sequential(\n",
    "            torchvision.transforms.RandomResizedCrop(size=[self.out_h, self.out_w], scale=(0.01, 1.0)),\n",
    "            torchvision.transforms.RandomRotation(degrees=20),\n",
    "            torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "            torchvision.transforms.RandomPerspective(distortion_scale=0.4, p=0.5),\n",
    "            torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            torchvision.transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
    "        )\n",
    "        x = transforms(x) # Apply random augmentations\n",
    "        # For more augmentations: https://pytorch.org/vision/0.19/transforms.html\n",
    "        return x\n",
    "    \n",
    "    def __reparameterize(self, x):\n",
    "\n",
    "        x = torch.nn.functional.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def set_output_shape(self, h, w):\n",
    "        self.out_h = h\n",
    "        self.out_w = w\n",
    "\n",
    "    def forward(self, batch_size):\n",
    "        x = self.__data\n",
    "        x = self.__reparameterize(x)\n",
    "        x = self.__augment(x, batch_size)\n",
    "        return x\n",
    "\n",
    "    def to_img(self):\n",
    "        with torch.no_grad():\n",
    "            x = self.__data\n",
    "            x = self.__reparameterize(x)\n",
    "        x = x.squeeze(0)\n",
    "        x = x.cpu()\n",
    "        x = x.numpy()\n",
    "        x = np.transpose(x, (1, 2, 0))\n",
    "        x = (x * 255).clip(0, 255)\n",
    "        x = x.astype(np.uint8)\n",
    "        pil_img = PIL.Image.fromarray(x)\n",
    "        return pil_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model, visualization and optimizer. You can select either ResNet50 or ViT-B/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet18(pretrained=True) # ResNet50\n",
    "# net = torchvision.models.vit_b_16(weights='IMAGENET1K_V1') # ViT-B/16\n",
    "\n",
    "preprocess_fn = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "model = NetworkWrapper(net, preprocess_fn).to(device)\n",
    "\n",
    "vis = Visualization(256, 256).to(device)\n",
    "vis.set_output_shape(224, 224)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=vis.parameters(),\n",
    "    lr=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = 852 # Selected ID for activation maximization from ImageNet1K (Tennis ball)\n",
    "\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    batch_size = 8\n",
    "    imgs = vis(batch_size).to(device)\n",
    "    outputs = model(imgs)\n",
    "    target_scores = outputs[:, class_index]\n",
    "\n",
    "    l2_regularization = torch.norm(imgs, p=2)\n",
    "    l2_lambda = 0.001 \n",
    "    regularization = l2_lambda * l2_regularization\n",
    "\n",
    "    loss = -torch.mean(target_scores) + regularization # Mean score loss + L2 regularization for activation maximization\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Iteration {i + 1}, Loss: {loss.item()}, L2 Regularization: {regularization.item()}\")\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Show visualization every 1000 iterations\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Image created at: Iteration {i + 1}, Loss: {loss.item()}\")\n",
    "        img = vis.to_img()\n",
    "        image_name = f\"visualization_{i + 1}.png\"\n",
    "        img.save(image_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
